{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory Assignment 2: Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals of the exercise\n",
    "This exercise has three parts: \n",
    "* The goal of the first part is to get more experience with supervised classification. We will use simple synthetic datasets and focus on the learning algorithms. \n",
    "\n",
    "* The goal of the second part is to consider the implementaion of the  Multi-layer feed forward neural network, often called Multi-layer perceptron (MLP).\n",
    "\n",
    "* The third part, which is the smallest one, is dedicated to evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Comparing classifiers\n",
    "## Datasets\n",
    "We start by making a synthetic dataset of 1600 datapoints and three classes, with 800 individuals in one class and 400 in each of the two other classes. (See https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs regarding how the data are generated.)\n",
    "\n",
    "When we are doing experiments in supervised learning, and the data are not already split into training and test sets, we should start by splitting the data. Sometimes there are natural ways to split the data, say training on data from one year and testing on data from a later year, but if that is not the case, we should shuffle the data randomly before splitting. (OK, that is not necessary with this particular synthetic data set, since it is already shuffled by default by scikit, but that will not be the case with real-world data.) We should split the data so that we keep the alignment between X and t, which may be achieved by shuffling the indices. We split into 50% for training, 25% for validation, and 25% for final testing. The set for final testing *must not be used* till the end of the assignment in part 3.\n",
    "\n",
    "We fix the seed both for data set generation and for shuffling, so that we work on the same datasets when we rerun the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, t = make_blobs(n_samples=[400,800,400], centers=[[0,0],[1,2],[2,3]], \n",
    "                  n_features=2, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1301,  293,  968,  624,  658,  574,  433,  368,  512,  353])"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(X.shape[0])\n",
    "random.seed(2020)\n",
    "random.shuffle(indices)\n",
    "indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[indices[:800],:]\n",
    "X_val = X[indices[800:1200],:]\n",
    "X_test = X[indices[1200:],:]\n",
    "t_train = t[indices[:800]]\n",
    "t_val = t[indices[800:1200]]\n",
    "t_test = t[indices[1200:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will  make a second dataset by merging the two smaller classes in (X,t) and call the new set (X, t2). This will be a binary set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_train = t_train == 1\n",
    "t2_train = t2_train.astype('int')\n",
    "t2_val = (t_val == 1).astype('int')\n",
    "t2_test = (t_test == 1).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the two training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the training sets \n",
    "def plotting(X, y, marker='.'):\n",
    "    labels = set(y)\n",
    "    for lab in labels:\n",
    "        plt.plot(X[y == lab][:, 1], X[y == lab][:, 0],marker, label=\"class {}\".format(lab))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plotting(X_train,t_train)\n",
    "plotting(X_train,t2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "We see that that set (X, t2) is far from linearly separable, and we will explore how various classifiers are able to handle this. We start with linear regression. You may use the implementation from exercise set week07 or make your own. You should make one improvement. The implementation week07 runs for a set number of epochs. You provide the number of epochs with a parameter to the fit-method. However, you do not know what a reasonable number of epochs is. Add one more argument to the fit-method *diff* (with defualt value e.g. 0.001). The training should stop when the update is less than *diff*. The *diff* will save training time, but it may also be wise to not set it too small -- and not run training for too long -- to avoid overfitting.\n",
    "\n",
    "We start by training the classifier on (X_train, t2_train) and test for accuracy on (X_val, t2_val) for various values of *diff*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for adding the bias into the X\n",
    "def add_bias(X):\n",
    "    # Put bias in position 0\n",
    "    sh = X.shape\n",
    "    if len(sh) == 1:\n",
    "        #X is a vector\n",
    "        return np.concatenate([np.array([1]), X])\n",
    "    else:\n",
    "        # X is a matrix\n",
    "        m = sh[0]\n",
    "        bias = np.ones((m,1)) # Makes a m*1 matrix of 1-s\n",
    "        return np.concatenate([bias, X], axis  = 1) \n",
    "\n",
    "def MSE(y,y_pred):\n",
    "    return sum((y - y_pred)**2) /y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyClassifier():\n",
    "    def accuracy(self,X_test, y_test, **kwargs):\n",
    "        \"\"\"Calculate the accuracy of the classifier\n",
    "        using the predict method\"\"\"\n",
    "        predictedValues = []\n",
    "        for a in X_test:\n",
    "            var = self.predict(a,**kwargs)\n",
    "            predictedValues.append(var)\n",
    "        equal = []\n",
    "        for b,c in zip(predictedValues,y_test):\n",
    "            if b == c:\n",
    "                equal.append((b,c))\n",
    "        accuracyVariable = len(equal)/len(y_test)\n",
    "        return accuracyVariable\n",
    "\n",
    "class LinRegClassifier(NumpyClassifier):\n",
    "    def fit(self, X_train, t_train, eta = 0.1, epochs=10,diff=0.001):\n",
    "        \"\"\"X_train is a Nxm matrix, N data points, m features\n",
    "        t_train are the targets values for training data\"\"\"\n",
    "\n",
    "        #Implementing the gradient descent:\n",
    "        (N,m) = X_train.shape\n",
    "        X_train = add_bias(X_train)\n",
    "        self.weights = weights = np.zeros(m+1)\n",
    "        \n",
    "        #defining the update with a large number\n",
    "        update = 100\n",
    "        \n",
    "        self.run = 0\n",
    "        \n",
    "        #the while loops goes on until the update is less than diff\n",
    "        while update > diff:\n",
    "            oldMSE = MSE(t_train,X_train @ weights)\n",
    "            \n",
    "            weights -= eta / N *  X_train.T @ (X_train @ weights - t_train)\n",
    "            \n",
    "            newMSE = MSE(t_train,X_train @ weights)\n",
    "            update = oldMSE - newMSE\n",
    "            self.run += 1\n",
    "        \n",
    "        \n",
    "    def predict(self, x, threshold=0.5):\n",
    "        z = add_bias(x)\n",
    "        score = z @ self.weights\n",
    "        return score>threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the linear regression classifier\n",
      "diff =0.100000000 | accuracy = 0.47000 | runs = 2\n",
      "diff =0.010000000 | accuracy = 0.47750 | runs = 3\n",
      "diff =0.001000000 | accuracy = 0.51000 | runs = 19\n",
      "diff =0.000100000 | accuracy = 0.56000 | runs = 51\n",
      "diff =0.000010000 | accuracy = 0.58000 | runs = 83\n",
      "diff =0.000001000 | accuracy = 0.60000 | runs = 115\n",
      "diff =0.000000100 | accuracy = 0.60500 | runs = 148\n",
      "diff =0.000000010 | accuracy = 0.60750 | runs = 180\n",
      "diff =0.000000001 | accuracy = 0.60750 | runs = 212\n",
      "Best accuracy: 0.60750 with diff = 1e-08\n"
     ]
    }
   ],
   "source": [
    "#training and validating the data\n",
    "def runingLinReg(X_train,t2_train,X_val,t2_val,printing):\n",
    "    print(\"Running the linear regression classifier\")\n",
    "\n",
    "    bestAcc_Lin = 0\n",
    "    diffLin = 0\n",
    "    for i in range(1,10,1):\n",
    "        d = 1/10**(i)\n",
    "        LinReg = LinRegClassifier()\n",
    "        LinReg.fit(X_train,t2_train,diff=d)\n",
    "        accuracy = LinReg.accuracy(X_val,t2_val)\n",
    "        if printing == True:\n",
    "            print(f'diff ={d:.9f} | accuracy = {accuracy:.5f} | runs = {LinReg.run}')\n",
    "\n",
    "        if accuracy > bestAcc_Lin:\n",
    "            bestAcc_Lin = accuracy\n",
    "            diffLin = d\n",
    "\n",
    "    return bestAcc_Lin,diffLin\n",
    "\n",
    "bestAcc_Lin,diffLin = runingLinReg(X_train,t2_train,X_val,t2_val,True)\n",
    "print(f\"Best accuracy: {bestAcc_Lin:4.5f} with diff = {diffLin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above that the *diff* variable is inversely proportional with the amount of runs the algorithm ran before it was terminated. Choosing the best diff is a tricky business since a small diff cause overfitting. However in this case the diff that gave the best accuracy is 0.000000001. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same for logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegClassifier(NumpyClassifier):\n",
    "    def fit(self, X_train, t_train, eta = 0.1, epochs=10,diff=0.001):\n",
    "        (k,m) = X_train.shape\n",
    "        X_train = add_bias(X_train)\n",
    "        \n",
    "        self.weights = weights = np.zeros(m+1)\n",
    "        \n",
    "        #defining the update with a large number\n",
    "        update = 100\n",
    "        \n",
    "        self.run = 0\n",
    "            \n",
    "        #the while loops goes on until the update is less than diff\n",
    "        while update > diff:\n",
    "            oldMSE = MSE(t_train,X_train @ weights)\n",
    "            weights -= eta / k *  X_train.T @ (self.forward(X_train) - t_train)\n",
    "            newMSE = MSE(t_train,X_train @ weights)\n",
    "            update = oldMSE - newMSE\n",
    "            self.run += 1\n",
    "    \n",
    "    def forward(self,X_train):\n",
    "        z = X_train @ self.weights\n",
    "        return logistic(z)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        z = add_bias(X)\n",
    "        score = self.forward(z)\n",
    "        return (score>0.5).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the logistic regression classifier\n",
      "diff =0.100000000 | accuracy = 0.58750 | runs = 1\n",
      "diff =0.010000000 | accuracy = 0.59500 | runs = 1\n",
      "diff =0.001000000 | accuracy = 0.60000 | runs = 1\n",
      "diff =0.000100000 | accuracy = 0.59750 | runs = 1\n",
      "diff =0.000010000 | accuracy = 0.59750 | runs = 1\n",
      "diff =0.000001000 | accuracy = 0.59750 | runs = 1\n",
      "diff =0.000000100 | accuracy = 0.59750 | runs = 1\n",
      "diff =0.000000010 | accuracy = 0.59750 | runs = 1\n",
      "diff =0.000000001 | accuracy = 0.59750 | runs = 1\n",
      "Best accuracy: 0.60000 with diff = 0.001\n"
     ]
    }
   ],
   "source": [
    "#training and validating the data\n",
    "def runingLogReg(X_train,t2_train,X_val,t2_val,printing):\n",
    "    print(\"Running the logistic regression classifier\")\n",
    "    bestAccLog = 0\n",
    "    best_diff = 0\n",
    "\n",
    "    for i in range(1,10,1):\n",
    "        d = 1/10**(i)\n",
    "        LogReg = LogRegClassifier()\n",
    "        LogReg.fit(X_train,t2_train,diff=d)\n",
    "        accuracy = LogReg.accuracy(X_val,t2_val)\n",
    "        if printing == True:\n",
    "            print(f'diff ={d:.9f} | accuracy = {accuracy:.5f} | runs = {LinReg.run}')\n",
    "\n",
    "        if accuracy > bestAccLog:\n",
    "            bestAccLog = accuracy\n",
    "            best_diff = d\n",
    "    return bestAccLog,best_diff\n",
    "    \n",
    "bestAccLog,best_diff = runingLogReg(X_train,t2_train,X_val,t2_val,True)\n",
    "print(f\"Best accuracy: {bestAccLog:4.5f} with diff = {best_diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *k*-nearest neighbors (*k*NN)\n",
    "We will now compare to the *k*-nearest neighbors classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def majority(a):\n",
    "    counts = Counter(a)\n",
    "    return counts.most_common()[0][0]\n",
    "\n",
    "def distance_L2(a, b):\n",
    "    s = sum((x - y) ** 2 for (x,y) in zip(a,b))\n",
    "    return s ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyClassifier():\n",
    "    def accuracy(self,X_test, y_test, **kwargs):\n",
    "        predictedValues = []\n",
    "        for a in X_test:\n",
    "            var = self.predict(a,**kwargs)\n",
    "            predictedValues.append(var)\n",
    "        equal = []\n",
    "        for b,c in zip(predictedValues,y_test):\n",
    "            if b == c:\n",
    "                equal.append((b,c))\n",
    "        accuracyVariable = len(equal)/len(y_test)\n",
    "        return accuracyVariable\n",
    "\n",
    "class kNNClassifier(PyClassifier):\n",
    "    def __init__(self, k=3, dist=distance_L2):\n",
    "        self.k = k\n",
    "        self.dist = dist\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def predict(self, a):\n",
    "        X = self.X_train\n",
    "        y = self.y_train\n",
    "        distances = [(self.dist(a, b), b, c) for (b, c) in zip(X, y)]\n",
    "        distances.sort()\n",
    "        predictors = [c for (_,_,c) in distances[0: k]]\n",
    "        return majority(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the kNN classifier\n",
      "k =  1.0 | Accuracy = 0.67000\n",
      "k =  2.0 | Accuracy = 0.67000\n",
      "k =  3.0 | Accuracy = 0.68000\n",
      "k =  4.0 | Accuracy = 0.68750\n",
      "k =  5.0 | Accuracy = 0.71250\n",
      "k =  6.0 | Accuracy = 0.72000\n",
      "k =  7.0 | Accuracy = 0.73500\n",
      "k =  8.0 | Accuracy = 0.73750\n",
      "k =  9.0 | Accuracy = 0.73250\n",
      "k = 10.0 | Accuracy = 0.74000\n",
      "k = 11.0 | Accuracy = 0.73750\n",
      "k = 12.0 | Accuracy = 0.75250\n",
      "k = 13.0 | Accuracy = 0.74750\n",
      "k = 14.0 | Accuracy = 0.76750\n",
      "k = 15.0 | Accuracy = 0.75250\n",
      "k = 16.0 | Accuracy = 0.75500\n",
      "k = 17.0 | Accuracy = 0.75000\n",
      "k = 18.0 | Accuracy = 0.75750\n",
      "k = 19.0 | Accuracy = 0.75250\n",
      "Best accuracy: 0.76750 at k = 14\n"
     ]
    }
   ],
   "source": [
    "print(\"Running the kNN classifier\")\n",
    "best_k = 0\n",
    "bestAccKnn = 0\n",
    "\n",
    "for k in range(1,20):\n",
    "    knnCL = kNNClassifier(k=k)\n",
    "    knnCL.fit(X_train,t2_train)\n",
    "    acc = knnCL.accuracy(X_val,t2_val)\n",
    "    if True:\n",
    "        print(f'k = {k:4.1f} | Accuracy = {acc:.5f}')\n",
    "    if acc > bestAccKnn:\n",
    "        bestAccKnn = acc\n",
    "        best_k = k\n",
    "print(f\"Best accuracy: {bestAccKnn:4.5f} at k = {best_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple perceptron\n",
    "Finally, runing the simple perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronClassifier(PyClassifier):\n",
    "    \"\"\"Simple perceptron python classifier\"\"\"\n",
    "    \n",
    "    def fit(self, X_train, y_train, eta=1, epochs=1):\n",
    "        \"\"\"Train the self.weights on the training data with learning\n",
    "        rate eta, running epochs many epochs\"\"\"\n",
    "        X_train = [[1] + list(x) for x in X_train]\n",
    "        dim = len(X_train[0])\n",
    "        weights = [0 for _ in range(dim)]\n",
    "        self.dim = dim \n",
    "        self.weights = weights\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            for x, t in zip(X_train,y_train):\n",
    "                y = int(self.forward(x)>0)\n",
    "                for i in range(dim):\n",
    "                    weights[i] -= eta * (y - t) * x[i]\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \"\"\"Calculate the score for the item x\"\"\"\n",
    "        score = sum([self.weights[i]*x[i] for i in range(self.dim)])\n",
    "        return score  \n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict the value for the item x\"\"\"\n",
    "        x = [1] + list(x)\n",
    "        score = self.forward(x)\n",
    "        return int(score > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Perceptron classifier\n",
      "Epoch:  1.0 | Accuracy = 0.6475\n",
      "Epoch:  2.0 | Accuracy = 0.65\n",
      "Epoch:  3.0 | Accuracy = 0.5925\n",
      "Epoch:  4.0 | Accuracy = 0.5875\n",
      "Epoch:  5.0 | Accuracy = 0.6475\n",
      "Epoch:  6.0 | Accuracy = 0.625\n",
      "Epoch:  7.0 | Accuracy = 0.5825\n",
      "Epoch:  8.0 | Accuracy = 0.65\n",
      "Epoch:  9.0 | Accuracy = 0.65\n",
      "Epoch: 10.0 | Accuracy = 0.595\n",
      "Epoch: 11.0 | Accuracy = 0.5825\n",
      "Epoch: 12.0 | Accuracy = 0.565\n",
      "Epoch: 13.0 | Accuracy = 0.6125\n",
      "Epoch: 14.0 | Accuracy = 0.6475\n",
      "Epoch: 15.0 | Accuracy = 0.5925\n",
      "Epoch: 16.0 | Accuracy = 0.5825\n",
      "Epoch: 17.0 | Accuracy = 0.6625\n",
      "Epoch: 18.0 | Accuracy = 0.5975\n",
      "Epoch: 19.0 | Accuracy = 0.595\n",
      "Best accuracy: 0.66250 after 17 epochs\n"
     ]
    }
   ],
   "source": [
    "def runingPer(X_train,t2_train,X_val,t2_val,printing):\n",
    "    print(\"Running the Perceptron classifier\")\n",
    "    bestAccPer = 0\n",
    "    bestEpochPer = 0\n",
    "    for i in range(1,20):\n",
    "        perCL = PerceptronClassifier()\n",
    "        perCL.fit(X_train,t2_train,epochs = i)\n",
    "        acc = perCL.accuracy(X_val,t2_val)\n",
    "        if printing == True:\n",
    "            print(f\"Epoch: {i:4.1f} | Accuracy = {acc}\")\n",
    "        if acc > bestAccPer:\n",
    "            bestAccPer = acc\n",
    "            bestEpochPer = i\n",
    "    return bestAccPer,bestEpochPer\n",
    "\n",
    "bestAccPer,bestEpochPer =runingPer(X_train,t2_train,X_val,t2_val,True)\n",
    "print(f\"Best accuracy: {bestAccPer:4.5f} after {bestEpochPer} epochs\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of classifier</th>\n",
       "      <th>Best accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.6075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.7675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name of classifier  Best accuracy\n",
       "0             Linear         0.6075\n",
       "1           Logistic         0.6000\n",
       "2                kNN         0.7675\n",
       "3         Perceptron         0.6625"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the table for the best accuracies \n",
    "import pandas as pd\n",
    "dict = {'Name of classifier' : ['Linear', 'Logistic', 'kNN', 'Perceptron'], \n",
    "        'Best accuracy' : [bestAcc_Lin, bestAccLog, bestAccKnn, bestAccPer]} \n",
    "df = pd.DataFrame(dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy for linear classifier is 0.6075, which seems all right. The linear classifier is a simple classifier, and one might not expected that this model gives us an accuracy at 1.00. The logistic classfier did worse than linear, the best acuracy was founded to 0.60 at diff = 0.001. I was not expecting the logistic to do better than linear classifier for the data (X,t2). (X, t2) is very far from linearly separable, and therefore models like linear and logistic, as both are parametric models, would not do a great job until the data is clearly inearly separable.\n",
    "\n",
    "The very best accuracy was founded to be for kNN classifier at 0.7675. This was actually expected, since kNN is non-parametric model and is not dependent on the linearly separability of the data. This model checks the points of the k-nearest neighbour. The best accuracy for perceptron classifier was at 0.6625 which is bit better than linear and logistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classifiers\n",
    "We turn to the task of classifying when there are more than two classes, and the task is to ascribe one class to each input. We will now use the set (X, t)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *k*NN\n",
    "One of the classifiers can handle multiple classes without modifications: the *k*-nearest neighbors classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the kNN classifier\n",
      "k =  1.0 | Accuracy = 0.66250\n",
      "k =  2.0 | Accuracy = 0.66250\n",
      "k =  3.0 | Accuracy = 0.67500\n",
      "k =  4.0 | Accuracy = 0.69000\n",
      "k =  5.0 | Accuracy = 0.70750\n",
      "k =  6.0 | Accuracy = 0.72250\n",
      "k =  7.0 | Accuracy = 0.73000\n",
      "k =  8.0 | Accuracy = 0.74500\n",
      "k =  9.0 | Accuracy = 0.74250\n",
      "k = 10.0 | Accuracy = 0.74500\n",
      "k = 11.0 | Accuracy = 0.74750\n",
      "k = 12.0 | Accuracy = 0.75500\n",
      "k = 13.0 | Accuracy = 0.75000\n",
      "k = 14.0 | Accuracy = 0.77000\n",
      "k = 15.0 | Accuracy = 0.75750\n",
      "k = 16.0 | Accuracy = 0.76000\n",
      "k = 17.0 | Accuracy = 0.75250\n",
      "k = 18.0 | Accuracy = 0.76000\n",
      "k = 19.0 | Accuracy = 0.75500\n",
      "\n",
      "Best accuracy: 0.77000 at k = 14\n"
     ]
    }
   ],
   "source": [
    "print(\"Running the kNN classifier\")\n",
    "bestAcc = 0\n",
    "bestK = 0\n",
    "\n",
    "for k in range(1,20):\n",
    "    knnCL = kNNClassifier(k=k)\n",
    "    knnCL.fit(X_train,t_train)\n",
    "    acc = knnCL.accuracy(X_val,t_val)\n",
    "    print(f'k = {k:4.1f} | Accuracy = {acc:.5f}')\n",
    "    if acc > bestAcc:\n",
    "        bestAcc = acc\n",
    "        bestK = k\n",
    "    \n",
    "print()\n",
    "print(f\"Best accuracy: {bestAcc:4.5f} at k = {bestK}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet again, the best accuracy was found at k = 14 but this time for the data set (X_train,t_train) and (X_val,t_val).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression \"one-vs-rest\"\n",
    "We saw in the lecture how a logistic regression classifier can be turned into a multi-class classifier using the one-vs-rest approach. We train one classifier for each class and assign the class which ascribes the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-vector -> t-matrix\n",
      "\n",
      "| 1 |  -> | 0   1   0 |\n",
      "| 1 |  -> | 0   1   0 |\n",
      "| 0 |  -> | 1   0   0 |\n",
      "| 1 |  -> | 0   1   0 |\n",
      "| 2 |  -> | 0   0   1 |\n",
      "| 0 |  -> | 1   0   0 |\n",
      "| 0 |  -> | 1   0   0 |\n",
      "| 2 |  -> | 0   0   1 |\n",
      "| 0 |  -> | 1   0   0 |\n",
      "| 2 |  -> | 0   0   1 |\n"
     ]
    }
   ],
   "source": [
    "#To modify the target values from scalars to arrays, we use the following technique (look at output)\n",
    "\n",
    "t = t_train[0:10]\n",
    "a = (t_train[0:10]==0).astype('int')\n",
    "b = (t_train[0:10]==1).astype('int')\n",
    "c = (t_train[0:10]==2).astype('int')\n",
    "print(\"t-vector -> t-matrix\")\n",
    "print()\n",
    "for i in range(10):\n",
    "    print(\"|\",t[i],\"|\",\" -> |\",a[i],\" \" ,b[i],\" \",c[i],\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy for one-vs-rest approach: 0.81\n"
     ]
    }
   ],
   "source": [
    "#training and finding the acccuracy of the classifier\n",
    "\n",
    "def oneVsRest(X_train,t_train,X_val,t_val):\n",
    "    bestAccuracy = -1\n",
    "    for i in range(3):\n",
    "        #converting from scalar to array:\n",
    "        t_train1 = (t_train==i).astype('int')\n",
    "        t_val1 = (t_val==i).astype('int')\n",
    "        \n",
    "        #fitting and calculating accuracy:\n",
    "        logReg = LogRegClassifier()\n",
    "        logReg.fit(X_train,t_train1)\n",
    "        accuracy = logReg.accuracy(X_val,t_val1)\n",
    "        \n",
    "        if accuracy > bestAccuracy:\n",
    "            bestAccuracy= accuracy\n",
    "    return bestAccuracy\n",
    "\n",
    "bestAccuracy = oneVsRest(X_train,t_train,X_val,t_val)\n",
    "\n",
    "print(f'Best accuracy for one-vs-rest approach: {bestAccuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both classifiers improves a bit. The accuracy for the kNN improves from 0.7675 to 0.7700. While the logistic regression \"on-vs-rest\" gets an accuracy of 0.81. The logistic regression \"on-vs-rest\" perfoms better since it is easier to deal with three separat classes rather than two. The very same can be said about kNN. kNN model becomes more stable with three classes and provides better result compared to binary dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding non-linear features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are returning to the binary classifier and the set (X, t2). As we see, some of the classifiers are not doing too well on the (X, t2) set. It is easy to see from the plot that this data set is not well suited for linear classifiers. There are several possible options for trying to learn on such a set. One is to construct new features from the original features to get better discriminants. This works e.g., for the XOR-problem. The current classifiers use two features: $x_1$ and $x_2$ (and a bias term $x_0$). Try to add three additional features of the form ${x_1}^2$, ${x_2}^2$, $x_1*x_2$ to the original features and see what the accuracies are now. Compare to the results for the original features in a 4x2 table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:                      [1.72075106 0.9695269 ]\n",
      "X_train with added features:  [1.72075106 0.9695269  2.9609842  0.9399824  1.66831443]\n"
     ]
    }
   ],
   "source": [
    "# adding the three additional features: \n",
    "\n",
    "def addingFeatures(X):\n",
    "    #founding the x1 and x2\n",
    "    x1 = X[:,0]\n",
    "    x2 = X[:,1]\n",
    "    \n",
    "    #defining the new features:\n",
    "    x1_2 = x1**2\n",
    "    x2_2 = x2**2\n",
    "    x1_x2 = x1 * x2\n",
    "    \n",
    "    #reshaping the x1,x2,x1x2 into column vectors in order to add them together with X\n",
    "    x1_2 = x1_2.reshape(x1_2.shape + (1,))\n",
    "    x2_2 = x2_2.reshape(x2_2.shape + (1,))\n",
    "    x1_x2 = x1_x2.reshape(x1_x2.shape + (1,))\n",
    "    \n",
    "    #adding the new features into X\n",
    "    X = np.concatenate([X,x1_2,x2_2,x1_x2],axis=1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "#testing the function:\n",
    "X = addingFeatures(X_train)\n",
    "print(\"X_train:                     \", X_train[0])\n",
    "print(\"X_train with added features: \",X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runingkNN(X_train,t2_train,X_val,t2_val,printing):\n",
    "    print(\"Running the kNN classifier\")\n",
    "    best_k = 0\n",
    "    bestAccKnn = 0\n",
    "\n",
    "    for k in range(1,20):\n",
    "        knnCL = kNNClassifier(k=k)\n",
    "        knnCL.fit(X_train,t2_train)\n",
    "        acc = knnCL.accuracy(X_val,t2_val)\n",
    "        if printing==True:\n",
    "            print(f'k = {k:4.1f} | Accuracy = {acc:.5f}')\n",
    "        if acc > bestAccKnn:\n",
    "            bestAccKnn = acc\n",
    "            best_k = k\n",
    "    return bestAccKnn,best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the linear regression classifier\n",
      "Running the logistic regression classifier\n",
      "Running the kNN classifier\n",
      "Running the Perceptron classifier\n"
     ]
    }
   ],
   "source": [
    "newX_train = addingFeatures(X_train)\n",
    "newX_val = addingFeatures(X_val)\n",
    "\n",
    "#Running the dataset with different classifiers:\n",
    "linAcc,d = runingLinReg(newX_train,t2_train,newX_val,t2_val,False)\n",
    "logAcc,d = runingLogReg(newX_train,t2_train,newX_val,t2_val,False)\n",
    "kNNAcc,k = runingkNN(newX_train,t2_train,newX_val,t2_val,False)\n",
    "perAcc,e =runingPer(newX_train,t2_train,newX_val,t2_val,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of classifier</th>\n",
       "      <th>Best accuracy</th>\n",
       "      <th>Best accuracy for added features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>0.6375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>0.6950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.6475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name of classifier  Best accuracy   Best accuracy for added features\n",
       "0             Linear          0.6075                            0.6375\n",
       "1           Logistic          0.6000                            0.6300\n",
       "2                kNN          0.7675                            0.6950\n",
       "3         Perceptron          0.6625                            0.6475"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the table for the best accuracies \n",
    "import pandas as pd\n",
    "dict = {'Name of classifier' : ['Linear', 'Logistic', 'kNN', 'Perceptron'], \n",
    "        'Best accuracy ' : [bestAcc_Lin, bestAccLog, bestAccKnn, bestAccPer],\n",
    "        'Best accuracy for added features':[linAcc,logAcc,kNNAcc,perAcc]} \n",
    "df = pd.DataFrame(dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding non-linear features boots the linear sepability of data which makes it easier to separat the data. This is the reason by models such as linear and logistic has increased in accuracy. kNN and perceptron on the other side have decreased in accuracy. This can be explained by the kNN is a non-parametric model which will by increased linear sepability get worse results. Same goes for perceptron since it cannot deal with non-linear features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II\n",
    "## Multi-layer neural networks\n",
    "We will implement the Multi-layer feed forward network (MLP, Marsland sec. 4.2.1). We will do so in two steps. In the first step, we will work concretely with the dataset (X, t). We will initialize the network and run a first round of training, i.e. one pass throught the algorithm at p. 78 in Marsland.\n",
    "\n",
    "In the second step, we will turn this code into a more general classifier. We can train and test this on (X, t), but also on other datasets.\n",
    "\n",
    "First of all, you should scale the X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to scale the data\n",
    "def scaling(X,X_train=X):\n",
    "    m = np.mean(X_train)\n",
    "    s = np.std(X_train)\n",
    "    return (X-m)/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: One round of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "We will only use one hidden layer. The number of nodes in the hidden layer will be a hyper-parameter provided by the user; let's call it *dim_hidden*. (*dim_hidden* is called *M* by Marsland.) Initially, we will set it to 6. This is a hyper-parameter where other values may give better results, and the hyper-parameter could be tuned.\n",
    "\n",
    "Another hyper-parameter set by the user is the learning rate. We set the initial value to 0.01, but also this may need tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01 #Learning rate\n",
    "dim_hidden = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the input *X_train* (after scaling) is a matrix of dimension *P x dim_in*, where *P* is the number of training instances, and *dim_in* is the number of features in the training instances (*L* in Marsland). Hence we can read *dim_in* off from *X_train*. Similarly, we can read *dim_out* off from *t_train*. Beware that *t_train* must be given the form of *P x dim_out* at some point, cf. the \"one-vs-all\" exercise above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the dimensions\n",
    "dim_in =  X_train.shape[1] #number of features in X_train  \n",
    "dim_out = len(set(t_train)) #number of values in t_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need two sets of weights: weights1 between the input and the hidden layer, and weights2, between the hidden layer and the output. Make the weight matrices and initialize them to small random numbers. Make sure that you take the bias terms into consideration and get the correct dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the weights by chosing small random numbers:\n",
    "\n",
    "weight1 = 0 #between input and hidden layer\n",
    "weight2 = 0 #between hidden and output\n",
    "\n",
    "#weights between input and hidden layer are going to be: dim_in * dim_hidden\n",
    "weight1 = np.random.rand(dim_in,dim_hidden)\n",
    "\n",
    "#weights between hidden and output layer are going to be: dim_hidden * dim_out \n",
    "weight2 = np.random.rand(dim_hidden,dim_out)\n",
    "\n",
    "#Initializing the biases by setting them to be -1\n",
    "bias_1 = -np.ones(dim_hidden)\n",
    "bias_2 = -np.ones(dim_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forwards phase\n",
    "We will run the first step in the training, and start with the forward phase. Calculate the activations after the hidden layer and after the output layer. We will follow Marsland and use the logistic (sigmoid) activation function in both layers. Inspect whether the results seem reasonable with respect to format and values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the activation of each neuron j in the hidden layers by:\n",
    "$$ a_c = g(h_c) = \\frac{1}{1+\\exp(- \\beta h_c + \\beta_0)} $$\n",
    "\n",
    "where $\\beta_0$ is the bias1, $\\beta$ is the weight1 and $h_c$ is the dot product of X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using weight1, bias and X_train to calculate activation\n",
    "#by using the algorithm at p.78 in Marshall:\n",
    "\n",
    "input1 = bias_1 + (X_train @ weight1)\n",
    "hidden_activations = logistic(input1)Rohullah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the activation of each neuron j in the hidden layers by:\n",
    "$$ y_k = g(h_k) = \\frac{1}{1+\\exp(- \\beta h_k + \\beta_0)} $$\n",
    "\n",
    "where $\\beta_0$ is the bias2, $\\beta$ is the weight2 and $h_k$ is hidden_activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the hidden_activations, weight2 and bias2 to calculate output_activations\n",
    "input2 = bias_2 + (hidden_activations @ weight2)\n",
    "output_activations = logistic(input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backwards phase\n",
    "Calculate the delta terms at the output. We assume, like Marsland, that we use sums of squared errors. (This amounts to the same as using the mean square error).\n",
    "\n",
    "#### ANSWER:\n",
    "\n",
    "Calculating the delta term at output by following formula: \n",
    "$$ \\delta_O (k) = (y_k - t_k)y_k(1-y_k)   $$\n",
    "$y_k$ is the output_activation and t_k is the targetvalue.\n",
    "\n",
    "Before we calculate delta for output, we must modify the dimension of t_train since it is (800,1) while \n",
    "output_activations has (800,3). We use the same technique as the one used for \"one-vs-rest\" approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranforming the t_train from (800,1) -> (800,3) or (800,2) depending of set of labels\n",
    "def transforming(t_train):\n",
    "    t_train_modified = np.zeros((len(t_train), len(set(t_train))))\n",
    "    if len(set(t_train)) == 3:\n",
    "        for t in t_train:\n",
    "            if t==0:\n",
    "                i = np.where(t_train==t)\n",
    "                t_train_modified[i] = [1,0,0]\n",
    "            elif t==1:\n",
    "                i = np.where(t_train==t)\n",
    "                t_train_modified[i] = [0,1,0]\n",
    "            elif t==2:\n",
    "                i = np.where(t_train==t)\n",
    "                t_train_modified[i] = [0,0,1]\n",
    "        return t_train_modified\n",
    "    else:\n",
    "        for t in t_train:\n",
    "            if t==0:\n",
    "                i = np.where(t_train==t)\n",
    "                t_train_modified[i] = [1,0]\n",
    "            elif t==1:\n",
    "                i = np.where(t_train==t)\n",
    "                t_train_modified[i] = [0,1]\n",
    "        return t_train_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_output = (output_activations - t_train_modified)*output_activations*(1-output_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the delta terms in the hidden layer.\n",
    "\n",
    "\n",
    "#### ANSWER: \n",
    "\n",
    "Computing the error at hidden layer using:\n",
    "$$\\delta_h = a_c(1 - a_c) \\sum _{k=1} ^N w_c \\delta_o $$\n",
    "where $a_c$ is the hidden activation and $\\sum _{k=1} ^N w_c \\delta_o$ can rewritten av dot product between delta_output and weight2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_hidden = hidden_activation * (1-hidden_activation) * (delta_output @ weight2.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the weights.\n",
    "Check that they have changed.\n",
    "As the weights depend on the random initialization, there is no unique correct solution at this point. But you should be able to see that the weights have been updated.\n",
    "\n",
    "#### ANSWER\n",
    "\n",
    "Updating the hidden layer weights:\n",
    "$$ v_l = v_l - \\eta \\delta_h x_l  $$\n",
    "\n",
    "Updating the output layer weights:\n",
    "$$ w_c = w_c - \\eta \\delta_o a_c  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1 -= eta*(X_train.T @ delta_hidden) \n",
    "weight2 -= eta*(hidden_activation.T @ delta_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 2: A Multi-layer neural network classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to train and test a classifier on (X, t). You could have put some parts of the code in the last step into a loop and run it through some iterations. But instead of copying code for every network we want to train, we will build a general Multi-layer neural network classfier as a class. This class will have some of the same structure as the classifiers we made for linear and logistic regression. The task consists mainly in copying in parts from what you did in step 1 into the template below. Remember to add the *self*- prefix where needed, and be careful in your use of variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNNClassifier():\n",
    "    \"\"\"A multi-layer neural network with one hidden layer\"\"\"\n",
    "\n",
    "    def __init__(self,eta = 0.01, dim_hidden = 6):\n",
    "        \"\"\"Initialize the hyperparameters\"\"\"\n",
    "        self.eta = eta\n",
    "        self.dim_hidden = dim_hidden\n",
    "\n",
    "    def fit(self, X_train, t_train, epochs = 100):\n",
    "        \"\"\"Initialize the weights. Train *epochs* many epochs.\"\"\"\n",
    "\n",
    "        # Initilaization\n",
    "        self.dim_in = dim_in= X_train.shape[1]\n",
    "        self.dim_out = dim_out = len(set(t_train))\n",
    "\n",
    "        #weights:\n",
    "        self.weight1 = weight1 = np.random.rand(dim_in,self.dim_hidden)\n",
    "        self.weight2 = weight2 = np.random.rand(self.dim_hidden,dim_out)\n",
    "\n",
    "        #biases:\n",
    "        self.bias_1 = bias_1 = -np.ones(self.dim_hidden)\n",
    "        self.bias_2 = bias_2 = -np.ones(dim_out)\n",
    "\n",
    "        #transforming t_train from (800,1) -> (800,3) or (800,2)\n",
    "        self.t= t = transforming(t_train)\n",
    "\n",
    "        for e in range(epochs):\n",
    "            # Run one epoch of forward-backward\n",
    "            hidden_activations,output_activations = self.forward(X_train)\n",
    "            self.backward(hidden_activations,output_activations,X_train)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"Perform one forward step.\n",
    "        Return a pair consisting of the outputs of the hidden_layer\n",
    "        and the outputs on the final layer\"\"\"\n",
    "        input1 = self.bias_1 + (X @ self.weight1)\n",
    "        hidden_activations = logistic(input1)\n",
    "\n",
    "        input2 = self.bias_2 + (hidden_activations @ self.weight2)\n",
    "        output_activations = logistic(input2)\n",
    "\n",
    "        return hidden_activations,output_activations\n",
    "\n",
    "    def backward(self,hidden_activations,output_activations,X):\n",
    "        #computing delta\n",
    "\n",
    "        self.delta_output=delta_output = (output_activations - self.t)*output_activations*(1-output_activations)\n",
    "        self.delta_hidden=delta_hidden = hidden_activations * (1-hidden_activations) * (delta_output @ self.weight2.T)\n",
    "\n",
    "        #updating the weights\n",
    "        self.weight1 -= self.eta*(X.T @ delta_hidden)\n",
    "        self.weight2 -= self.eta*(hidden_activations.T @ delta_output)\n",
    "\n",
    "    def accuracy(self,X_test, y_test, **kwargs):\n",
    "\n",
    "        predictedValues = []\n",
    "        for a in X_test:\n",
    "            var = self.predict(a,**kwargs)\n",
    "            predictedValues.append(var)\n",
    "        equal = []\n",
    "        for b,c in zip(predictedValues,y_test):\n",
    "            if b==c:\n",
    "                equal.append((b,c))\n",
    "        accuracyVariable = len(equal)/len(y_test)\n",
    "        return accuracyVariable\n",
    "\n",
    "    def predict(self,X):\n",
    "        hidden_activations,output_activations = self.forward(X)\n",
    "        #returning the max of the output_activations\n",
    "        return output_activations.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network on (X_train, t_train) (after scaling), and test on (X_val, t_val). Adjust hyperparameters or number of epochs if you are not content with the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.7600\n",
      "2) accuracy = 0.7625\n",
      "3) accuracy = 0.7575\n",
      "4) accuracy = 0.7600\n",
      "5) accuracy = 0.7600\n",
      "6) accuracy = 0.7575\n",
      "7) accuracy = 0.7600\n",
      "8) accuracy = 0.7600\n",
      "9) accuracy = 0.7625\n",
      "10) accuracy = 0.7600\n"
     ]
    }
   ],
   "source": [
    "#scaling the data:\n",
    "X_train_scaled = scaling(X_train)\n",
    "X_val_scaled = scaling(X_val,X_train)\n",
    "\n",
    "#training and predicting 10 times:\n",
    "for i in range(10):\n",
    "    MNN = MNNClassifier(eta=0.01)\n",
    "    MNN.fit(X_train_scaled,t_train,500)\n",
    "    accMNN = MNN.accuracy(X_val_scaled,t_val)\n",
    "    print(f\"{i+1}) accuracy = {accMNN:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a neural network classifier for (X,t)\n",
    "Let us see whether a multilayer neural network can learn a non-linear classifier.\n",
    "Train it on (X_train, t2_train) and test it on (X_val, t2_val).\n",
    "Tune the hyper-parameters for the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.7550\n",
      "2) accuracy = 0.7550\n",
      "3) accuracy = 0.7550\n",
      "4) accuracy = 0.7550\n",
      "5) accuracy = 0.7550\n",
      "6) accuracy = 0.7575\n",
      "7) accuracy = 0.7550\n",
      "8) accuracy = 0.7550\n",
      "9) accuracy = 0.7575\n",
      "10) accuracy = 0.7525\n"
     ]
    }
   ],
   "source": [
    "#training and predicting on a non-linear classifer\n",
    "for i in range(10):\n",
    "    mnnc = MNNClassifier()\n",
    "    mnnc.fit(X_train_scaled,t2_train,500)\n",
    "    accNonLin = mnnc.accuracy(X_val_scaled,t2_val)\n",
    "    print(f\"{i+1}) accuracy = {accNonLin:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like that the multilayer neural network can actually learn a non-linear classifier quite good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Final testing\n",
    "Take the best classifiers that you found for the training sets (X, t) and (X, t2) and test them on (X_test, t_test) and (X_test, t2_test), respectively. Compute accuracy, the confusion matrix, precision and recall. Answer in 2-3 sentences: How do the accuracies compare to the results on the validation sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "def cf_matrix(predicted, gold,size):\n",
    "    #making confusion matrix for (2,2)\n",
    "    print(\"--CONFUSION MATRIX--\")\n",
    "    if size ==2:\n",
    "        table = np.zeros((size,size))\n",
    "        for p,g in zip(predicted, gold):\n",
    "            table[int(p), g] +=1\n",
    "        print(28*\" \"+\"gold\")\n",
    "        print(\"{:20}|{:>9}|{:>9}|\".format(\" \",\"neg\", \"pos\"))\n",
    "        print(10*\" \"+30*\"-\")\n",
    "        print(\"{:10}{:10}|{:9}|{:9}|\".format(\" \",\"neg\",table[0,0], table[0,1]))\n",
    "        print(\"predicted \"+30*\"-\")\n",
    "        print(\"{:10}{:10}|{:9}|{:9}|\".format(\" \",\"pos\",table[1,0], table[1,1]))\n",
    "        print(10*\" \"+30*\"-\")\n",
    "        \n",
    "    else: #making confusion matrix for (3,3)\n",
    "        table = np.zeros((size,size))\n",
    "        for p,g in zip(predicted, gold):\n",
    "            table[int(p), g] += 1\n",
    "        print(28*\" \"+\"gold\")\n",
    "        print(\"{:20}|{:>9}|{:>9}|\".format(\" \",\"\", \"\"))\n",
    "        print(10*\" \"+30*\"-\")\n",
    "        print(\"{:10}{:10}|{:9}|{:9}|\".format(\" \",table[0,0],table[0,1], table[0,2]))\n",
    "        print(\"predicted \"+30*\"-\")\n",
    "        print(\"{:10}{:10}|{:9}|{:9}|\".format(\" \",table[1,0],table[1,1], table[1,2]))\n",
    "        print(10*\" \"+30*\"-\")\n",
    "        print(\"{:10}{:10}|{:9}|{:9}|\".format(\" \",table[2,0],table[2,1], table[2,2]))\n",
    "        print(10*\" \"+30*\"-\")\n",
    "    \n",
    "    #calculating the accuracy, Precision and recall\n",
    "    N = 0\n",
    "    M = 0\n",
    "    for t in table:\n",
    "        N += np.sum(t)\n",
    "        M += t[0]\n",
    "    print(f\"Accuracy: {(np.sum(table.diagonal()))/N} \")\n",
    "    print(f\"Precision: {table[0,0]/np.sum(table[0])}\")\n",
    "    print(f\"Recall: {table[0,0]/M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running kNN: training on (X,t) and testing on (X_test,t_test)\n",
      "--CONFUSION MATRIX--\n",
      "                            gold\n",
      "                    |         |         |\n",
      "          ------------------------------\n",
      "                69.0|      7.0|      0.0|\n",
      "predicted ------------------------------\n",
      "                23.0|    161.0|     42.0|\n",
      "          ------------------------------\n",
      "                 0.0|     27.0|     71.0|\n",
      "          ------------------------------\n",
      "Accuracy: 0.7525 \n",
      "Precision: 0.9078947368421053\n",
      "Recall: 0.75\n"
     ]
    }
   ],
   "source": [
    "#From above we can see that the kNN and MNN were the best classifiers. Therefore, we will continue with them:\n",
    "\n",
    "\n",
    "#running kNN:\n",
    "print(\"Running kNN: training on (X,t) and testing on (X_test,t_test)\")\n",
    "best_k1 = 0\n",
    "bestkNN_accuracy1 = 0\n",
    "for k in range(1,20):\n",
    "    knnCL = kNNClassifier(k=k)\n",
    "    knnCL.fit(X_train,t_train)\n",
    "    acc = knnCL.accuracy(X_test,t_test)\n",
    "    if acc > bestkNN_accuracy1:\n",
    "        bestkNN_accuracy1 = acc\n",
    "        best_k1 = k\n",
    "\n",
    "#printing the confusion matrix using the k\n",
    "CL1 = kNNClassifier(k=best_k1)\n",
    "CL1.fit(X_train,t_train)\n",
    "predicted = [CL1.predict(x) for x in X_test]\n",
    "cf_matrix(predicted, t_test,len(set(t_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running kNN: training on (X,t2) and testing on (X_test,t2_test)\n",
      "--CONFUSION MATRIX--\n",
      "                            gold\n",
      "                    |      neg|      pos|\n",
      "          ------------------------------\n",
      "          neg       |    142.0|     35.0|\n",
      "predicted ------------------------------\n",
      "          pos       |     63.0|    160.0|\n",
      "          ------------------------------\n",
      "Accuracy: 0.755 \n",
      "Precision: 0.8022598870056498\n",
      "Recall: 0.6926829268292682\n"
     ]
    }
   ],
   "source": [
    "print(\"Running kNN: training on (X,t2) and testing on (X_test,t2_test)\")\n",
    "best_k2 = 0\n",
    "bestkNN_accuracy2 = 0\n",
    "for k in range(1,20):\n",
    "    knnCL = kNNClassifier(k=k)\n",
    "    knnCL.fit(X_train,t2_train)\n",
    "    acc = knnCL.accuracy(X_test,t2_test)\n",
    "    if acc > bestkNN_accuracy2:\n",
    "        bestkNN_accuracy2 = acc\n",
    "        best_k2 = k\n",
    "        \n",
    "#printing the confusion matrix using the k\n",
    "CL2 = kNNClassifier(k=best_k2)\n",
    "CL2.fit(X_train,t2_train)\n",
    "predicted2 = [CL2.predict(x) for x in X_test]\n",
    "cf_matrix(predicted2, t2_test,len(set(t2_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MNN: training on (X,t) and testing on (X_test,t_test)\n",
      "--CONFUSION MATRIX--\n",
      "                            gold\n",
      "                    |         |         |\n",
      "          ------------------------------\n",
      "                67.0|      7.0|      0.0|\n",
      "predicted ------------------------------\n",
      "                24.0|    140.0|     21.0|\n",
      "          ------------------------------\n",
      "                 1.0|     48.0|     92.0|\n",
      "          ------------------------------\n",
      "Accuracy: 0.7475 \n",
      "Precision: 0.9054054054054054\n",
      "Recall: 0.7282608695652174\n"
     ]
    }
   ],
   "source": [
    "#running MNN \n",
    "\n",
    "X_train_scaled = scaling(X_train)\n",
    "X_test_scaled = scaling(X_test,X_train)\n",
    "\n",
    "print(\"Running MNN: training on (X,t) and testing on (X_test,t_test)\")\n",
    "MNN_CL1 = MNNClassifier(eta=0.01)\n",
    "MNN_CL1.fit(X_train,t_train,500)\n",
    "predicted1 = [MNN_CL1.predict(x) for x in X_test]\n",
    "cf_matrix(predicted1, t_test,len(set(t_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MNN: training on (X,t2) and testing on (X_test,t2_test)\n",
      "--CONFUSION MATRIX--\n",
      "                            gold\n",
      "                    |      neg|      pos|\n",
      "          ------------------------------\n",
      "          neg       |    164.0|     64.0|\n",
      "predicted ------------------------------\n",
      "          pos       |     41.0|    131.0|\n",
      "          ------------------------------\n",
      "Accuracy: 0.7375 \n",
      "Precision: 0.7192982456140351\n",
      "Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "#running MNN \n",
    "\n",
    "print(\"Running MNN: training on (X,t2) and testing on (X_test,t2_test)\")\n",
    "MNN_accuracy2 = 0\n",
    "for i in range(20):\n",
    "    MNN = MNNClassifier(eta=0.01)\n",
    "    MNN.fit(X_train_scaled,t2_train,500)\n",
    "    accMNN = MNN.accuracy(X_test_scaled,t2_test)\n",
    "    if accMNN > MNN_accuracy2:\n",
    "        MNN_accuracy2 = accMNN\n",
    "\n",
    "MNN_CL2 = MNNClassifier(eta=0.01)\n",
    "MNN_CL2.fit(X_train,t2_train,500)\n",
    "predicted2 = [MNN_CL2.predict(x) for x in X_test]\n",
    "cf_matrix(predicted2, t2_test,len(set(t2_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best accuracy for kNN, I had to run the classifier 20 times and find the k that gave the best accuracy. Based on that, I calculated the confusion matrix, accuracy, recall and precision. This ended up with an accuracy at around 0.725 for training on (X,t) and testing on (X_test,t_test), and at 0.750 for training on (X,t2) and testing on (X_test,t2_test). However, the MNN-classifier did a bit worse on accuracy. The reason for that could be that I did not run the MNN classifier enough times. The best results were at 0.7475 for training on (X,t) and testing on (X_test,t_test) and 0.7375 for the other data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
